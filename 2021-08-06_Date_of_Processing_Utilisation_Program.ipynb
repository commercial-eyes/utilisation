{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "import requests\n",
    "from requests_html import HTML\n",
    "from datetime import date\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def default_parameters(fmt, start_dt, end_dt):\n",
    "    defaults = {\n",
    "        # scheme and state\n",
    "        0: {\n",
    "            'PROGRAM': '%2Fstatistics%2Fpbs_csv',\n",
    "            'REPIND': 'pbs_tab1',\n",
    "            'RPT_FMT': '1',\n",
    "            'cond': '+',\n",
    "            'START_DT': start_dt,\n",
    "            'END_DT': end_dt,\n",
    "            'list': '',\n",
    "            'fyear': '+',\n",
    "            'year': '+',\n",
    "            'by': '+',\n",
    "            'statefmt': '%24statefw.',\n",
    "            'vdim': 'newitem*%28scheme+all%29',\n",
    "            'vdim2': '%28scheme%3D%27All+items%27+all%29',\n",
    "            'hdim': '%28STATE+ALL%29*_replace_*SUM%3D%27+%27',\n",
    "            'rts': '30',\n",
    "            'title1': ''\n",
    "        },\n",
    "        # monthly scheme and state\n",
    "        1: {\n",
    "            'PROGRAM': '%2Fstatistics%2Fpbs_csv',\n",
    "            'REPIND': 'pbs_tab1',\n",
    "            'RPT_FMT': '2',\n",
    "            'cond': '+',\n",
    "            'START_DT': start_dt,\n",
    "            'END_DT': end_dt,\n",
    "            'list': '',\n",
    "            'fyear': '+',\n",
    "            'year': '+',\n",
    "            'by': '+',\n",
    "            'statefmt': '%24statefw.',\n",
    "            'vdim': 'newitem*%28scheme+all%29',\n",
    "            'vdim2': '*%28MOP+ALL%29+%28MOP%3D%27All+items%27+all%29',\n",
    "            'hdim': '%28STATE+ALL%29*_replace_*SUM%3D%27+%27',\n",
    "            'rts': '30',\n",
    "            'title1': ''\n",
    "        },\n",
    "        # FY scheme and state\n",
    "        2: {\n",
    "            'PROGRAM': '%2Fstatistics%2Fpbs_csv',\n",
    "            'REPIND': 'pbs_tab1',\n",
    "            'RPT_FMT': '3',\n",
    "            'cond': '+',\n",
    "            'START_DT': start_dt,\n",
    "            'END_DT': end_dt,\n",
    "            'list': '',\n",
    "            'fyear': 'fyear',\n",
    "            'year': '+',\n",
    "            'by': '+',\n",
    "            'statefmt': '%24statefw.',\n",
    "            'vdim': 'newitem*%28scheme+all%29',\n",
    "            'vdim2': '*%28fyear+ALL%29+%28fyear%3D%27All+items%27+all%29',\n",
    "            'hdim': '%28STATE+ALL%29*_replace_*SUM%3D%27+%27',\n",
    "            'rts': '30',\n",
    "            'title1': ''\n",
    "        },\n",
    "        # CY scheme and state\n",
    "        3: {\n",
    "            'PROGRAM': '%2Fstatistics%2Fpbs_csv',\n",
    "            'REPIND': 'pbs_tab1',\n",
    "            'RPT_FMT': '4',\n",
    "            'cond': '+',\n",
    "            'START_DT': start_dt,\n",
    "            'END_DT': end_dt,\n",
    "            'list': '',\n",
    "            'fyear': '+',\n",
    "            'year': 'year',\n",
    "            'by': '+',\n",
    "            'statefmt': '%24statefw.',\n",
    "            'vdim': 'newitem*%28scheme+all%29',\n",
    "            'vdim2': '*%28year+ALL%29+%28year%3D%27All+items%27+all%29',\n",
    "            'hdim': '%28STATE+ALL%29*_replace_*SUM%3D%27+%27',\n",
    "            'rts': '30',\n",
    "            'title1': ''\n",
    "        },\n",
    "        # patient category\n",
    "        4: {\n",
    "            'PROGRAM': '%2Fstatistics%2Fpbs_csv',\n",
    "            'REPIND': 'pbs_tab1',\n",
    "            'RPT_FMT': '5',\n",
    "            'cond': '+',\n",
    "            'START_DT': start_dt,\n",
    "            'END_DT': end_dt,\n",
    "            'list': '',\n",
    "            'fyear': '+',\n",
    "            'year': '+',\n",
    "            'by': '+',\n",
    "            'statefmt': '%24statefw.',\n",
    "            'vdim': 'newitem',\n",
    "            'vdim2': 'all',\n",
    "            'hdim': '%28scheme%3D%27%27*patcat%3D%27%27+ALL%29*_replace_*SUM%3D%27+%27',\n",
    "            'rts': '30',\n",
    "            'title1': ''\n",
    "        },\n",
    "        # month and patient category\n",
    "        5: {\n",
    "            'PROGRAM': '%2Fstatistics%2Fpbs_csv',\n",
    "            'REPIND': 'pbs_tab1',\n",
    "            'RPT_FMT': '6',\n",
    "            'cond': '+',\n",
    "            'START_DT': start_dt,\n",
    "            'END_DT': end_dt,\n",
    "            'list': '',\n",
    "            'fyear': '+',\n",
    "            'year': '+',\n",
    "            'by': '+',\n",
    "            'statefmt': '%24statefw.',\n",
    "            'vdim': 'newitem',\n",
    "            'vdim2': '*%28MOP+ALL%29+%28MOP%3D%27All+items%27+all%29',\n",
    "            'hdim': '%28scheme%3D%27%27*patcat%3D%27%27+ALL%29*_replace_*SUM%3D%27+%27',\n",
    "            'rts': '30',\n",
    "            'title1': ''\n",
    "        },\n",
    "        # FY and patient category\n",
    "        6: {\n",
    "            'PROGRAM': '%2Fstatistics%2Fpbs_csv',\n",
    "            'REPIND': 'pbs_tab1',\n",
    "            'RPT_FMT': '7',\n",
    "            'cond': '+',\n",
    "            'START_DT': start_dt,\n",
    "            'END_DT': end_dt,\n",
    "            'list': '',\n",
    "            'fyear': 'fyear',\n",
    "            'year': '+',\n",
    "            'by': '+',\n",
    "            'statefmt': '%24statefw.',\n",
    "            'vdim': 'newitem',\n",
    "            'vdim2': '*%28fyear+ALL%29+%28fyear%3D%27All+items%27+all%29',\n",
    "            'hdim': '%28scheme%3D%27%27*patcat%3D%27%27+ALL%29*_replace_*SUM%3D%27+%27',\n",
    "            'rts': '30',\n",
    "            'title1': ''\n",
    "        },\n",
    "        # CY and patient category\n",
    "        7: {\n",
    "            'PROGRAM': '%2Fstatistics%2Fpbs_csv',\n",
    "            'REPIND': 'pbs_tab1',\n",
    "            'RPT_FMT': '8',\n",
    "            'cond': '+',\n",
    "            'START_DT': start_dt,\n",
    "            'END_DT': end_dt,\n",
    "            'list': '',\n",
    "            'fyear': '+',\n",
    "            'year': 'year',\n",
    "            'by': '+',\n",
    "            'statefmt': '%24statefw.',\n",
    "            'vdim': 'newitem',\n",
    "            'vdim2': '*%28year+ALL%29+%28year%3D%27All+items%27+all%29',\n",
    "            'hdim': '%28scheme%3D%27%27*patcat%3D%27%27+ALL%29*_replace_*SUM%3D%27+%27',\n",
    "            'rts': '30',\n",
    "            'title1': ''\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return defaults[fmt]\n",
    "\n",
    "format_selection = {\n",
    "    'Rows': {0: 'Scheme',\n",
    "  1: 'Scheme + Month',\n",
    "  2: 'Scheme + Financial year',\n",
    "  3: 'Scheme + Calendar year',\n",
    "  4: '',\n",
    "  5: 'Month',\n",
    "  6: 'Financial year',\n",
    "  7: 'Calendar year'},\n",
    " 'Columns': {0: 'State',\n",
    "  1: 'State',\n",
    "  2: 'State',\n",
    "  3: 'State',\n",
    "  4: 'Patient category',\n",
    "  5: 'Patient category',\n",
    "  6: 'Patient category',\n",
    "  7: 'Patient category'}\n",
    "}\n",
    "\n",
    "def add_zeros(text):\n",
    "    while len(text) < 6:\n",
    "        text = '0' + str(text)\n",
    "    return text\n",
    "\n",
    "def grouper(chunk_size, item_codes):\n",
    "    \"\"\"\n",
    "    Groups item codes into chunks of size n and returns a generator object\n",
    "    Checks for instances of 'ITEM_CODE' and removes before returning\n",
    "    \"\"\"\n",
    "    \n",
    "    it = iter(item_codes)\n",
    "    while True:\n",
    "        chunk = tuple(itertools.islice(it, chunk_size))\n",
    "        if any(code == 'ITEM_CODE' for code in chunk):\n",
    "            chunk = list(chunk)\n",
    "            chunk.remove('ITEM_CODE')\n",
    "            chunk = tuple(chunk)\n",
    "        if not chunk:\n",
    "            return\n",
    "        yield chunk\n",
    "        \n",
    "def generate_download_urls(fmt, start_dt, end_dt, item_codes, base_url):\n",
    "    \"\"\"\n",
    "    Returns a generator of all the URLs needed to download\n",
    "    \"\"\"\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    for chunk in item_codes:        \n",
    "        for report_type in ('SERVICES', 'BENEFIT'):\n",
    "            params = default_parameters(fmt, start_dt, end_dt)\n",
    "            # 'hdim' contains _replace_ which we replace with the report type required\n",
    "            params['hdim'] = params['hdim'].replace('_replace_', report_type)\n",
    "            params['list'] = '%27' + '%27%2C%27'.join(chunk) + '%27'\n",
    "            \n",
    "            url = base_url\n",
    "            \n",
    "            # concatenate parameters to form url\n",
    "            for key, value in params.items():\n",
    "                url += key + '=' + value + '&'\n",
    "                \n",
    "            # remove last & from url\n",
    "            url = url[:-1]\n",
    "            \n",
    "            res.append((chunk, url, fmt))\n",
    "            \n",
    "    return res\n",
    "\n",
    "def download_urls(urls, item_map):\n",
    "    \"\"\"\n",
    "    Uses generator expression to download list of URLs.\n",
    "    Returns list of item codes which failed to download (if any).\n",
    "    \"\"\"\n",
    "\n",
    "    dl_fail_log = []\n",
    "    df_list = []\n",
    "    \n",
    "    for chunk, url, fmt in tqdm(urls, desc='Downloading...'):\n",
    "        if url.find('SERVICES') != -1:\n",
    "            report_type = 'SERVICES'\n",
    "        else:\n",
    "            report_type = 'BENEFIT'\n",
    "            \n",
    "        df = get_data(url, report_type)\n",
    "        if not isinstance(df, pd.DataFrame):\n",
    "            dl_fail_log.extend(chunk)\n",
    "            continue\n",
    "        \n",
    "        df_list.append(df)\n",
    "    \n",
    "    if dl_fail_log:\n",
    "        print('Some downloads failed. See dl_fail_log.')\n",
    "    \n",
    "    print('Cleaning up...')\n",
    "    df = pd.concat(df_list, sort=False)\n",
    "    print('Done!')\n",
    "    \n",
    "    return df, dl_fail_log\n",
    "\n",
    "def get_data(url, report_type):\n",
    "    \"\"\"\n",
    "    Returns the downloaded data as a cleaned dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    data = pd.read_html(url) # returns as list\n",
    "    if len(data) == 2:       # empty dataset\n",
    "        return None\n",
    "    \n",
    "    df = data[1]\n",
    "    return clean_df(df, report_type)\n",
    "    \n",
    "\n",
    "def clean_df(df, report_type):\n",
    "    \"\"\"\n",
    "    Cleans the .xls item reports format and returns a df\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df.droplevel(level=[0,2], axis=1)\n",
    "    df.rename(columns={df.columns[0]:'Item Code', df.columns[1]:'Date'}, inplace=True)\n",
    "    df.columns = [\n",
    "        col.replace('Free', '').replace('SafetyNet', 'Safety Net')\n",
    "        for col in df.columns\n",
    "    ]\n",
    "\n",
    "    df = df[(~df['Item Code'].isin(df['Date'].unique())) & (df['Date']!='Total')]\n",
    "\n",
    "    df['Report_Type'] = report_type\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "    return df\n",
    "\n",
    "def item_code_lookup(df, item_map):\n",
    "    \"\"\"\n",
    "    Merges item report data with PBS item drug map data\n",
    "    \"\"\"\n",
    "    \n",
    "    df['ItemCodeLookup'] = df['Item Code'].map(lambda x: '0' * (6 -len(x)) + x)\n",
    "    df = df.merge(item_map, \n",
    "                  left_on='ItemCodeLookup', \n",
    "                  right_on='ITEM_CODE')\n",
    "    \n",
    "    df.drop(['ItemCodeLookup','ITEM_CODE'], axis=1, inplace=True)\n",
    "    \n",
    "    df.rename(columns={'DRUG_NAME':'Item Name','FORM/STRENGTH':'Formulation','ATC5_Code':'ATC Code'},\n",
    "              inplace=True)\n",
    "    \n",
    "    df['Item Name'] = df['Item Name'].str.title()\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_item_map():\n",
    "    \"\"\"\n",
    "    Downloads the PBS item drug map and saves into local dir. Returns this as a dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    item_map_url = 'https://www.pbs.gov.au/statistics/dos-and-dop/files/pbs-item-drug-map.csv'\n",
    "    r = requests.get(item_map_url)\n",
    "    with open('pbs-item-drug-map.csv', 'wb') as f:\n",
    "        f.write(r.content)\n",
    "    return pd.read_csv('pbs-item-drug-map.csv', encoding='latin-1')\n",
    "\n",
    "def get_item_codes(item_map, n):\n",
    "    \"\"\"\n",
    "    Returns the chunked (into size n) item codes from the PBS item drug map\n",
    "    \"\"\"\n",
    "    \n",
    "    return grouper(n, item_map.ITEM_CODE.unique())\n",
    "\n",
    "def get_dates():\n",
    "    \"\"\"\n",
    "    Gets the valid dates for item reports data\n",
    "    \"\"\"\n",
    "    \n",
    "    r = requests.get('http://medicarestatistics.humanservices.gov.au/statistics/pbs_item.jsp')\n",
    "\n",
    "    html = HTML(html=r.content)\n",
    "\n",
    "    dropdown = html.find('select[name=end_dt]')[0]\n",
    "    return [tag.attrs['value'] for tag in dropdown.find('option')]\n",
    "\n",
    "def run_program():\n",
    "    \"\"\"\n",
    "    User prompts to run script.\n",
    "    \"\"\"\n",
    "    \n",
    "    dates = get_dates()\n",
    "    \n",
    "    print(f'Data available from {dates[0]} to {dates[-1]}\\n')\n",
    "    start_dt = input('Enter desired start date for downloads in format YYYYMM\\n')\n",
    "    end_dt = input('\\nEnter desired start date for downloads in format YYYYMM\\n')\n",
    "    \n",
    "    item_map = get_item_map()\n",
    "    item_codes = get_item_codes(item_map, 400)\n",
    "\n",
    "    base_url = 'http://medicarestatistics.humanservices.gov.au/statistics/do.jsp?_'\n",
    "    \n",
    "    urls = generate_download_urls(5, start_dt, end_dt, item_codes, base_url)\n",
    "    \n",
    "    df, dl_fail_log = download_urls(urls, item_map)\n",
    "    \n",
    "    while True:\n",
    "        save_choice = input('Save downloaded dataset to local DIR? Y/N\\n').lower()\n",
    "        if save_choice in ('y', 'n'):\n",
    "            break\n",
    "        \n",
    "    if save_choice == 'y':\n",
    "        \n",
    "        today = date.today()\n",
    "        today = today.strftime('%Y-%m-%d')\n",
    "        \n",
    "        df.to_csv(f'{today}_{start_dt}_{end_dt}_Date_of_Processing_Utilisation.csv', index=False)\n",
    "    \n",
    "    return df, dl_fail_log\n",
    "\n",
    "df, dl_fail_log = run_program()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
